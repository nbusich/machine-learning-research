{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.resnet import resnet50\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def sim(z_i, z_j):\n",
    "    \"\"\"Normalized dot product between two vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - z_i: 1xD tensor.\n",
    "    - z_j: 1xD tensor.\n",
    "    \n",
    "    Returns:\n",
    "    - A scalar value that is the normalized dot product between z_i and z_j.\n",
    "    \"\"\"\n",
    "    norm_dot_product = None\n",
    "    num = z_i @ z_j\n",
    "    denom = torch.linalg.norm(z_i) * torch.linalg.norm(z_j)\n",
    "    norm_dot_product = num/denom\n",
    "    return norm_dot_product"
   ],
   "id": "ff35ce2489fa76cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def sim_positive_pairs(out_left, out_right):\n",
    "    \"\"\"Normalized dot product between positive pairs.\n",
    "\n",
    "    Inputs:\n",
    "    - out_left: NxD tensor; output of the projection head g(), left branch in SimCLR model.\n",
    "    - out_right: NxD tensor; output of the projection head g(), right branch in SimCLR model.\n",
    "    Each row is a z-vector for an augmented sample in the batch.\n",
    "    The same row in out_left and out_right form a positive pair.\n",
    "    \n",
    "    Returns:\n",
    "    - A Nx1 tensor; each row k is the normalized dot product between out_left[k] and out_right[k].\n",
    "    \"\"\"\n",
    "    pos_pairs = None\n",
    "    \n",
    "    # Compute the normalized head projection outputs over each row of features\n",
    "    norm_left = out_left / torch.linalg.norm(out_left, dim=1, keepdim=True)\n",
    "    norm_right = out_right / torch.linalg.norm(out_right, dim=1, keepdim=True)\n",
    "\n",
    "    # Compute the diagonal dot product directly by multiplying and summing\n",
    "    pos_pairs = (norm_left * norm_right).sum(dim=1, keepdim=True)\n",
    "    \n",
    "    return pos_pairs"
   ],
   "id": "6b221f3263c3b7cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_sim_matrix(out):\n",
    "    \"\"\"Compute a 2N x 2N matrix of normalized dot products between all pairs of augmented examples in a batch.\n",
    "\n",
    "    Inputs:\n",
    "    - out: 2N x D tensor; each row is the z-vector (output of projection head) of a single augmented example.\n",
    "    There are a total of 2N augmented examples in the batch.\n",
    "    \n",
    "    Returns:\n",
    "    - sim_matrix: 2N x 2N tensor; each element i, j in the matrix is the normalized dot product between out[i] and out[j].\n",
    "    \"\"\"\n",
    "    sim_matrix = None\n",
    "    \n",
    "    norm_out = out / torch.linalg.norm(out, dim=1, keepdim=True)\n",
    "    sim_matrix = norm_out @ norm_out.T\n",
    "\n",
    "    return sim_matrix"
   ],
   "id": "6416da8b3c031e66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def simclr_loss_vectorized(out_left, out_right, tau, device='cuda'):\n",
    "    \"\"\"Compute the contrastive loss L over a batch (vectorized version). No loops are allowed.\n",
    "    \n",
    "    Inputs and output are the same as in simclr_loss_naive.\n",
    "    \"\"\"\n",
    "    N = out_left.shape[0]\n",
    "    \n",
    "    # Concatenate out_left and out_right into a 2*N x D tensor.\n",
    "    out = torch.cat([out_left, out_right], dim=0)  # [2*N, D]\n",
    "    \n",
    "    # Compute similarity matrix between all pairs of augmented examples in the batch.\n",
    "    sim_matrix = compute_sim_matrix(out)  # [2*N, 2*N]\n",
    "    \n",
    "    # Step 1: Use sim_matrix to compute the denominator value for all augmented samples.\n",
    "    exponential = torch.exp(sim_matrix/tau)\n",
    "    \n",
    "    # This binary mask zeros out terms where k=i.\n",
    "    mask = (torch.ones_like(exponential, device=device) - torch.eye(2 * N, device=device)).to(device).bool()\n",
    "    \n",
    "    # We apply the binary mask.\n",
    "    exponential = exponential.masked_select(mask).view(2 * N, -1)  # [2*N, 2*N-1]\n",
    "    \n",
    "    # Hint: Compute the denominator values for all augmented samples. This should be a 2N x 1 vector.\n",
    "    denom = torch.sum(exponential, axis = 1)\n",
    "    \n",
    "    # Step 2: Compute similarity between positive pairs.\n",
    "    # You can do this in two ways: \n",
    "    # Option 1: Extract the corresponding indices from sim_matrix. \n",
    "    # Option 2: Use sim_positive_pairs().\n",
    "    similarity_vector = sim_positive_pairs(out_left, out_right) # shape (2,1)\n",
    "    \n",
    "    # Step 3: Compute the numerator value for all augmented samples.\n",
    "    numerator = None\n",
    "    numerator = torch.exp(similarity_vector/tau)\n",
    "    \n",
    "    # Step 4: Now that you have the numerator and denominator for all augmented samples, compute the total loss.\n",
    "    loss = -torch.log(numerator/denom).mean()\n",
    "    return loss"
   ],
   "id": "2408b31aa743fead"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_train_transform(seed=123456):\n",
    "    \"\"\"\n",
    "    This function returns a composition of data augmentations to a single training image.\n",
    "    Complete the following lines. Hint: look at available functions in torchvision.transforms\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    \n",
    "    # Transformation that applies color jitter with brightness=0.4, contrast=0.4, saturation=0.4, and hue=0.1\n",
    "    color_jitter = transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  \n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        \n",
    "        # Step 1: Randomly resize and crop to 32x32.\n",
    "        transforms.RandomResizedCrop(size = (32,32)),\n",
    "\n",
    "        # Step 2: Horizontally flip the image with probability 0.5\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "        # Step 3: With a probability of 0.8, apply color jitter (you can use \"color_jitter\" defined above.\n",
    "        transforms.RandomApply([color_jitter],p=0.8),\n",
    "\n",
    "        # Step 4: With a probability of 0.2, convert the image to grayscale\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "    return train_transform"
   ],
   "id": "b4c9dfeeabdd40ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CIFAR10Pair(CIFAR10):\n",
    "    \"\"\"\n",
    "    CIFAR10 Dataset.\n",
    "    \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        x_i = None\n",
    "        x_j = None\n",
    "\n",
    "        if self.transform is not None:\n",
    "            \n",
    "            x_i = self.transform(img)\n",
    "            x_j = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return x_i, x_j, target"
   ],
   "id": "845dd943fd60e29f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_test_transform():\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "    return test_transform"
   ],
   "id": "286a3802d419f4d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.f = []\n",
    "        for name, module in resnet50().named_children():\n",
    "            if name == 'conv1':\n",
    "                module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            if not isinstance(module, nn.Linear) and not isinstance(module, nn.MaxPool2d):\n",
    "                self.f.append(module)\n",
    "        # encoder\n",
    "        self.f = nn.Sequential(*self.f)\n",
    "        # projection head\n",
    "        self.g = nn.Sequential(nn.Linear(2048, 512, bias=False), nn.BatchNorm1d(512),\n",
    "                               nn.ReLU(inplace=True), nn.Linear(512, feature_dim, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f(x)\n",
    "        feature = torch.flatten(x, start_dim=1)\n",
    "        out = self.g(feature)\n",
    "        return F.normalize(feature, dim=-1), F.normalize(out, dim=-1)"
   ],
   "id": "5b37e943876dff52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(model, data_loader, train_optimizer, epoch, epochs, batch_size=32, temperature=0.5, device='cuda'):\n",
    "    \"\"\"Trains the model defined in ./model.py with one epoch.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: Model class object as defined in ./model.py.\n",
    "    - data_loader: torch.utils.data.DataLoader object; loads in training data. You can assume the loaded data has been augmented.\n",
    "    - train_optimizer: torch.optim.Optimizer object; applies an optimizer to training.\n",
    "    - epoch: integer; current epoch number.\n",
    "    - epochs: integer; total number of epochs.\n",
    "    - batch_size: Number of training samples per batch.\n",
    "    - temperature: float; temperature (tau) parameter used in simclr_loss_vectorized.\n",
    "    - device: the device name to define torch tensors.\n",
    "\n",
    "    Returns:\n",
    "    - The average loss.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n",
    "    for data_pair in train_bar:\n",
    "        x_i, x_j, target = data_pair\n",
    "        x_i, x_j = x_i.to(device), x_j.to(device)\n",
    "        \n",
    "        out_left, out_right, loss = None, None, None\n",
    "        \n",
    "        out_left = model.forward(x_i)\n",
    "        out_right = model.forward(x_j)\n",
    "        total_loss += simclr_loss_vectorized(out_left, out_right, temperature, device='cuda')\n",
    "        \n",
    "        train_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_optimizer.step()\n",
    "\n",
    "        total_num += batch_size\n",
    "        total_loss += loss.item() * batch_size\n",
    "        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n",
    "\n",
    "    return total_loss / total_num"
   ],
   "id": "10796da42539cec6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_val(model, data_loader, train_optimizer, epoch, epochs, device='cuda'):\n",
    "    is_train = train_optimizer is not None\n",
    "    model.train() if is_train else model.eval()\n",
    "    loss_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    total_loss, total_correct_1, total_correct_5, total_num, data_bar = 0.0, 0.0, 0.0, 0, tqdm(data_loader)\n",
    "    with (torch.enable_grad() if is_train else torch.no_grad()):\n",
    "        for data, target in data_bar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            out = model(data)\n",
    "            loss = loss_criterion(out, target)\n",
    "\n",
    "            if is_train:\n",
    "                train_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                train_optimizer.step()\n",
    "\n",
    "            total_num += data.size(0)\n",
    "            total_loss += loss.item() * data.size(0)\n",
    "            prediction = torch.argsort(out, dim=-1, descending=True)\n",
    "            total_correct_1 += torch.sum((prediction[:, 0:1] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
    "            total_correct_5 += torch.sum((prediction[:, 0:5] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
    "\n",
    "            data_bar.set_description('{} Epoch: [{}/{}] Loss: {:.4f} ACC@1: {:.2f}% ACC@5: {:.2f}%'\n",
    "                                     .format('Train' if is_train else 'Test', epoch, epochs, total_loss / total_num,\n",
    "                                             total_correct_1 / total_num * 100, total_correct_5 / total_num * 100))\n",
    "\n",
    "    return total_loss / total_num, total_correct_1 / total_num * 100, total_correct_5 / total_num * 100\n"
   ],
   "id": "5a7462c1ca2e6c6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def test(model, memory_data_loader, test_data_loader, epoch, epochs, c, temperature=0.5, k=200, device='cuda'):\n",
    "    model.eval()\n",
    "    total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\n",
    "    with torch.no_grad():\n",
    "        # generate feature bank\n",
    "        for data, _, target in tqdm(memory_data_loader, desc='Feature extracting'):\n",
    "            feature, out = model(data.to(device))\n",
    "            feature_bank.append(feature)\n",
    "        # [D, N]\n",
    "        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
    "        # [N]\n",
    "        feature_labels = torch.tensor(memory_data_loader.dataset.targets, device=feature_bank.device)\n",
    "        # loop test data to predict the label by weighted knn search\n",
    "        test_bar = tqdm(test_data_loader)\n",
    "        for data, _, target in test_bar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            feature, out = model(data)\n",
    "\n",
    "            total_num += data.size(0)\n",
    "            # compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
    "            sim_matrix = torch.mm(feature, feature_bank)\n",
    "            \n",
    "            # [B, K]\n",
    "            sim_weight, sim_indices = sim_matrix.topk(k=k, dim=-1)\n",
    "            # [B, K]\n",
    "            sim_labels = torch.gather(feature_labels.expand(data.size(0), -1), dim=-1, index=sim_indices)\n",
    "            sim_weight = (sim_weight / temperature).exp()\n",
    "\n",
    "            # counts for each class\n",
    "            one_hot_label = torch.zeros(data.size(0) * k, c, device=device)\n",
    "            # [B*K, C]\n",
    "            one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n",
    "            # weighted score ---> [B, C]\n",
    "            pred_scores = torch.sum(one_hot_label.view(data.size(0), -1, c) * sim_weight.unsqueeze(dim=-1), dim=1)\n",
    "\n",
    "            pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
    "            total_top1 += torch.sum((pred_labels[:, :1] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
    "            total_top5 += torch.sum((pred_labels[:, :5] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
    "            test_bar.set_description('Test Epoch: [{}/{}] Acc@1:{:.2f}% Acc@5:{:.2f}%'\n",
    "                                     .format(epoch, epochs, total_top1 / total_num * 100, total_top5 / total_num * 100))\n",
    "\n",
    "    return total_top1 / total_num * 100, total_top5 / total_num * 100"
   ],
   "id": "19ab5e37c0d4a938"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T20:24:20.740159Z",
     "start_time": "2025-04-08T20:24:20.544098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Do not modify this cell.\n",
    "feature_dim = 128\n",
    "temperature = 0.5\n",
    "k = 200\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "percentage = 0.1\n",
    "pretrained_path = './pretrained_model/trained_simclr_model.pth'\n",
    "\n",
    "train_transform = compute_train_transform()\n",
    "train_data = CIFAR10(root='data', train=True, transform=train_transform, download=True)\n",
    "trainset = torch.utils.data.Subset(train_data, list(np.arange(int(len(train_data) * percentage))))\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "test_transform = compute_test_transform()\n",
    "test_data = CIFAR10(root='data', train=False, transform=test_transform, download=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "model = Classifier(num_class=len(train_data.classes))\n",
    "model.load_state_dict(torch.load(pretrained_path, map_location='cpu'), strict=False)\n",
    "model = model.to(device)\n",
    "for param in model.f.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "flops, params = profile(model, inputs=(torch.randn(1, 3, 32, 32).to(device),))\n",
    "flops, params = clever_format([flops, params])\n",
    "print('# Model Params: {} FLOPs: {}'.format(params, flops))\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "pretrain_results = {'train_loss': [], 'train_acc@1': [], 'train_acc@5': [],\n",
    "                    'test_loss': [], 'test_acc@1': [], 'test_acc@5': []}\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc_1, train_acc_5 = train_val(model, train_loader, optimizer, epoch, epochs)\n",
    "    pretrain_results['train_loss'].append(train_loss)\n",
    "    pretrain_results['train_acc@1'].append(train_acc_1)\n",
    "    pretrain_results['train_acc@5'].append(train_acc_5)\n",
    "    test_loss, test_acc_1, test_acc_5 = train_val(model, test_loader, None, epoch, epochs)\n",
    "    pretrain_results['test_loss'].append(test_loss)\n",
    "    pretrain_results['test_acc@1'].append(test_acc_1)\n",
    "    pretrain_results['test_acc@5'].append(test_acc_5)\n",
    "    if test_acc_1 > best_acc:\n",
    "        best_acc = test_acc_1\n",
    "\n",
    "# Print the best test accuracy. You should see a best top-1 accuracy of >=70%.\n",
    "print('Best top-1 accuracy with self-supervised learning: ', best_acc)"
   ],
   "id": "1e8bfab386f994f3",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_train_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m percentage \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.1\u001B[39m\n\u001B[1;32m      8\u001B[0m pretrained_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./pretrained_model/trained_simclr_model.pth\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 10\u001B[0m train_transform \u001B[38;5;241m=\u001B[39m compute_train_transform()\n\u001B[1;32m     11\u001B[0m train_data \u001B[38;5;241m=\u001B[39m CIFAR10(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, transform\u001B[38;5;241m=\u001B[39mtrain_transform, download\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     12\u001B[0m trainset \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mSubset(train_data, \u001B[38;5;28mlist\u001B[39m(np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(train_data) \u001B[38;5;241m*\u001B[39m percentage))))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'compute_train_transform' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ddc8116debdb9022"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
